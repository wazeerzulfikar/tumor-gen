{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/om/user/wazeer/deform_gan/src/utils.py:84: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import random\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# third-party imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import multi_gpu_model \n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import nibabel as nib\n",
    "from skimage import transform\n",
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# project imports\n",
    "import datagenerators\n",
    "import networks\n",
    "import losses\n",
    "import utils\n",
    "import unet\n",
    "\n",
    "sys.path.append('ext/neuron')\n",
    "import neuron.callbacks as nrn_gen\n",
    "\n",
    "sess = tf.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SimpleITK as sitk\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import cv2\n",
    "\n",
    "\n",
    "# def show(x):\n",
    "#     plt.imshow(sitk.GetArrayFromImage(x),'gray')\n",
    "    \n",
    "# def resample(image, transform):\n",
    "#     reference_image = image\n",
    "#     interpolator = sitk.sitkLinear\n",
    "#     default_value = 100.0\n",
    "#     return sitk.Resample(image, transform,\n",
    "#                         interpolator, default_value)\n",
    "\n",
    "# def distance(p1,p2):\n",
    "#     return np.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x1 = []\n",
    "y = []\n",
    "for f in sorted(glob.glob('sample_data/orig/*.jpg')):\n",
    "    x.append(plt.imread(f)[:,:,0])\n",
    "for f in sorted(glob.glob('sample_data/masks/*.jpg')):\n",
    "    x1.append(plt.imread(f)[:,:,0])\n",
    "for f in sorted(glob.glob('sample_data/transformed/*.jpg')):\n",
    "    y.append(plt.imread(f)[:,:,0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x))\n",
    "print(len(x))\n",
    "print(x[0].shape)\n",
    "\n",
    "# for i in range(len(x)):\n",
    "#     plt.imshow(x[i],'gray')\n",
    "#     plt.show()\n",
    "#     plt.imshow(x1[i],'gray')\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.imshow(y[i],'gray')\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "input_shape = (img_size, img_size, 1)\n",
    "\n",
    "x = np.array(x).reshape((-1,)+input_shape)/255.\n",
    "x1 = np.array(x1).reshape((-1,)+input_shape)/255.\n",
    "y = np.array(y).reshape((-1,)+input_shape)/255.\n",
    "y1 = np.repeat(np.zeros_like(y),repeats=2,axis=-1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_size, img_size, 1)\n",
    "src = tf.keras.layers.Input(input_shape)\n",
    "mask = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "reload(networks)\n",
    "\n",
    "nf_enc = [16, 32, 32, 32]\n",
    "nf_dec = [32, 32, 32, 32, 8, 8]\n",
    "\n",
    "model = networks.generator(src, mask, nf_enc, nf_dec, flow_out=False)\n",
    "outputs = model.outputs\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# model.fit([x,x1], y, epochs=5, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0010\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.9804e-04\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 0.0010\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0010\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.9241e-04\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 9.9207e-04\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0010\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 9.9244e-04\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 9.9240e-04\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.0010\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 4s 7ms/step - loss: 0.0010\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0011\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 0.0011\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 9.9690e-04\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 9.9363e-04\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 9.7179e-04\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 9.7073e-04\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 9.7976e-04\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 9.7778e-04\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 9.9313e-04\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.8199e-04\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.9433e-04\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.9805e-04\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.9195e-04\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.6654e-04\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.6073e-04\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.6316e-04\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.9291e-04\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.8737e-04\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.8395e-04\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5655e-04\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5664e-04\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.6086e-04\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4114e-04\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4901e-04\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3982e-04\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.6412e-04\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5907e-04\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5889e-04\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4818e-04\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5154e-04\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.8073e-04\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.7126e-04\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.7744e-04\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5000e-04\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2745e-04\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3321e-04\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4995e-04\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.6456e-04\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3898e-04\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4612e-04\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5857e-04\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4714e-04\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3605e-04\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3659e-04\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3484e-04\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.7281e-04\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4254e-04\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3707e-04\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3460e-04\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3191e-04\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3184e-04\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2289e-04\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1814e-04\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2381e-04\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3450e-04\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2439e-04\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1725e-04\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.4489e-04\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3394e-04\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1786e-04\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2087e-04\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3012e-04\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3375e-04\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.5607e-04\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2463e-04\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2682e-04\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2718e-04\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.0094e-04\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1591e-04\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1631e-04\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1245e-04\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1318e-04\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1203e-04\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.1324e-04\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.0533e-04\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.0677e-04\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 3s 5ms/step - loss: 9.0767e-04\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 3s 6ms/step - loss: 8.9943e-04\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 8.9939e-04\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.2179e-04\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 3s 5ms/step - loss: 9.3276e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b3a8e31aba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x,x1], y, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=np.random.randint(len(x))\n",
    "plt.imshow(np.squeeze(y[i]),'gray')\n",
    "plt.show()\n",
    "\n",
    "pred = model.predict([x[i:i+1], x1[i:i+1]])\n",
    "\n",
    "plt.imshow(np.squeeze(pred[0]),'gray')\n",
    "plt.show()\n",
    "\n",
    "# plt.imshow(pred[1][0][:,:,0],'gray')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(pred[1][0][:,:,1],'gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = []\n",
    "for x_,x1_ in zip(x,x1):\n",
    "    y1.append(np.squeeze(model.predict([[x_], [x1_]])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0000000e+00 1.8998687e-06 1.8998688e-06 ... 9.9999243e-01 9.9999619e-01\n",
      " 1.0000000e+00]\n",
      "(256, 256)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b9785bedd30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.unique((y1)))\n",
    "print(y1[0].shape)\n",
    "plt.imshow(y1[10],'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_y = np.array(y1).reshape((-1,)+input_shape)\n",
    "gan_x = np.copy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 128, 128, 16) 160         input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 128, 128, 16) 64          conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_304 (LeakyReLU)     (None, 128, 128, 16) 0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 64, 64, 32)   4640        leaky_re_lu_304[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 64, 64, 32)   128         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_305 (LeakyReLU)     (None, 64, 64, 32)   0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 32, 32, 32)   9248        leaky_re_lu_305[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 32, 32, 32)   128         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_306 (LeakyReLU)     (None, 32, 32, 32)   0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 16, 16, 32)   9248        leaky_re_lu_306[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 16, 16, 32)   128         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_307 (LeakyReLU)     (None, 16, 16, 32)   0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 16, 16, 32)   9248        leaky_re_lu_307[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 16, 16, 32)   128         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_308 (LeakyReLU)     (None, 16, 16, 32)   0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_76 (UpSampling2D) (None, 32, 32, 32)   0           leaky_re_lu_308[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 32, 32, 64)   0           up_sampling2d_76[0][0]           \n",
      "                                                                 leaky_re_lu_306[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 32, 32, 32)   18464       concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 32, 32, 32)   128         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_309 (LeakyReLU)     (None, 32, 32, 32)   0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_77 (UpSampling2D) (None, 64, 64, 32)   0           leaky_re_lu_309[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 64, 64, 64)   0           up_sampling2d_77[0][0]           \n",
      "                                                                 leaky_re_lu_305[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 64, 64, 32)   18464       concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 64, 64, 32)   128         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_310 (LeakyReLU)     (None, 64, 64, 32)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_78 (UpSampling2D) (None, 128, 128, 32) 0           leaky_re_lu_310[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 128, 128, 48) 0           up_sampling2d_78[0][0]           \n",
      "                                                                 leaky_re_lu_304[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 128, 128, 32) 13856       concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 128, 128, 32) 128         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_311 (LeakyReLU)     (None, 128, 128, 32) 0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 128, 128, 32) 9248        leaky_re_lu_311[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 128, 128, 32) 128         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_312 (LeakyReLU)     (None, 128, 128, 32) 0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_79 (UpSampling2D) (None, 256, 256, 32) 0           leaky_re_lu_312[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 256, 256, 33) 0           up_sampling2d_79[0][0]           \n",
      "                                                                 input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 256, 256, 16) 4768        concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 256, 256, 16) 64          conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_313 (LeakyReLU)     (None, 256, 256, 16) 0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 256, 256, 16) 2320        leaky_re_lu_313[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 256, 256, 16) 64          conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_314 (LeakyReLU)     (None, 256, 256, 16) 0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flow (Conv2D)                   (None, 256, 256, 2)  290         leaky_re_lu_314[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "spatial_transformer_19 (Spatial (None, 256, 256, 1)  0           input_23[0][0]                   \n",
      "                                                                 flow[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 101,170\n",
      "Trainable params: 100,562\n",
      "Non-trainable params: 608\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 256, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_341 (Conv2D)          (None, 128, 128, 32)      544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_315 (LeakyReLU)  (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_342 (Conv2D)          (None, 64, 64, 64)        32832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_288 (Bat (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_316 (LeakyReLU)  (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_343 (Conv2D)          (None, 32, 32, 128)       131200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_289 (Bat (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_317 (LeakyReLU)  (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_344 (Conv2D)          (None, 16, 16, 256)       524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_290 (Bat (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_318 (LeakyReLU)  (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_345 (Conv2D)          (None, 16, 16, 1)         257       \n",
      "=================================================================\n",
      "Total params: 691,169\n",
      "Trainable params: 690,273\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, g_loss 0.5463 d_loss 0.1674, time 47.3693\n",
      "Epoch 1, g_loss 0.5596 d_loss 0.1641, time 226.139\n",
      "Epoch 2, g_loss 0.56 d_loss 0.164, time 262.4469\n",
      "Epoch 3, g_loss 0.5601 d_loss 0.1639, time 298.6747\n",
      "Epoch 4, g_loss 0.5604 d_loss 0.1639, time 334.6922\n",
      "Epoch 5, g_loss 0.5605 d_loss 0.1638, time 370.8046\n",
      "Epoch 6, g_loss 0.5609 d_loss 0.1636, time 406.9019\n",
      "Epoch 7, g_loss 0.5612 d_loss 0.1634, time 442.9195\n",
      "Epoch 8, g_loss 0.562 d_loss 0.163, time 478.9251\n",
      "Epoch 9, g_loss 0.5629 d_loss 0.1627, time 514.5194\n",
      "Epoch 10, g_loss 0.564 d_loss 0.1621, time 549.9319\n",
      "Epoch 11, g_loss 0.564 d_loss 0.1621, time 585.347\n",
      "Epoch 12, g_loss 0.5639 d_loss 0.1622, time 621.0043\n",
      "Epoch 13, g_loss 0.5633 d_loss 0.1625, time 656.6341\n",
      "Epoch 14, g_loss 0.5631 d_loss 0.1625, time 692.1578\n",
      "Epoch 15, g_loss 0.5635 d_loss 0.1623, time 727.7261\n",
      "Epoch 16, g_loss 0.5638 d_loss 0.1621, time 763.5039\n",
      "Epoch 17, g_loss 0.5641 d_loss 0.162, time 799.2115\n",
      "Epoch 18, g_loss 0.5644 d_loss 0.1619, time 835.1011\n",
      "Epoch 19, g_loss 0.5647 d_loss 0.1617, time 870.6934\n",
      "Epoch 20, g_loss 0.565 d_loss 0.1615, time 906.2505\n",
      "Epoch 21, g_loss 0.5653 d_loss 0.1613, time 941.7868\n",
      "Epoch 22, g_loss 0.566 d_loss 0.1609, time 977.2107\n",
      "Epoch 23, g_loss 0.5666 d_loss 0.1605, time 1012.6427\n",
      "Epoch 24, g_loss 0.5673 d_loss 0.1601, time 1048.2654\n",
      "Epoch 25, g_loss 0.5685 d_loss 0.1594, time 1083.9047\n",
      "Epoch 26, g_loss 0.569 d_loss 0.1591, time 1119.4041\n",
      "Epoch 27, g_loss 0.5702 d_loss 0.1584, time 1154.9005\n",
      "Epoch 28, g_loss 0.5711 d_loss 0.1578, time 1190.5743\n",
      "Epoch 29, g_loss 0.5726 d_loss 0.157, time 1226.2271\n",
      "Epoch 30, g_loss 0.5741 d_loss 0.1563, time 1261.7195\n",
      "Epoch 31, g_loss 0.5758 d_loss 0.1554, time 1297.5952\n",
      "Epoch 32, g_loss 0.5777 d_loss 0.1545, time 1333.8079\n",
      "Epoch 33, g_loss 0.5787 d_loss 0.1541, time 1369.6899\n",
      "Epoch 34, g_loss 0.58 d_loss 0.1539, time 1405.5655\n",
      "Epoch 35, g_loss 0.5805 d_loss 0.1537, time 1441.7535\n",
      "Epoch 36, g_loss 0.5811 d_loss 0.1535, time 1478.037\n",
      "Epoch 37, g_loss 0.5816 d_loss 0.1533, time 1514.2356\n",
      "Epoch 38, g_loss 0.5816 d_loss 0.1535, time 1549.9631\n",
      "Epoch 39, g_loss 0.5818 d_loss 0.1534, time 1585.5599\n",
      "Epoch 40, g_loss 0.5823 d_loss 0.1532, time 1621.4558\n",
      "Epoch 41, g_loss 0.5831 d_loss 0.1532, time 1657.638\n",
      "Epoch 42, g_loss 0.5854 d_loss 0.152, time 1693.6572\n",
      "Epoch 43, g_loss 0.5862 d_loss 0.1517, time 1729.804\n",
      "Epoch 44, g_loss 0.5867 d_loss 0.1515, time 1766.0152\n",
      "Epoch 45, g_loss 0.5873 d_loss 0.1516, time 1802.2016\n",
      "Epoch 46, g_loss 0.5877 d_loss 0.1515, time 1838.3725\n",
      "Epoch 47, g_loss 0.5878 d_loss 0.1513, time 1874.3425\n",
      "Epoch 48, g_loss 0.5881 d_loss 0.1511, time 1910.2348\n",
      "Epoch 49, g_loss 0.5887 d_loss 0.1508, time 1945.8251\n",
      "Epoch 50, g_loss 0.5877 d_loss 0.1516, time 1981.2669\n",
      "Epoch 51, g_loss 0.5881 d_loss 0.1511, time 2016.0515\n",
      "Epoch 52, g_loss 0.5882 d_loss 0.151, time 2051.7527\n",
      "Epoch 53, g_loss 0.5885 d_loss 0.1509, time 2087.5256\n",
      "Epoch 54, g_loss 0.5886 d_loss 0.1509, time 2122.526\n",
      "Epoch 55, g_loss 0.5891 d_loss 0.1506, time 2157.2713\n",
      "Epoch 56, g_loss 0.5889 d_loss 0.1507, time 2192.4694\n",
      "Epoch 57, g_loss 0.5888 d_loss 0.1507, time 2227.842\n",
      "Epoch 58, g_loss 0.5887 d_loss 0.1509, time 2263.5846\n",
      "Epoch 59, g_loss 0.5888 d_loss 0.1507, time 2299.3569\n",
      "Epoch 60, g_loss 0.5881 d_loss 0.1515, time 2335.057\n",
      "Epoch 61, g_loss 0.589 d_loss 0.1505, time 2370.7196\n",
      "Epoch 62, g_loss 0.5892 d_loss 0.1504, time 2406.345\n",
      "Epoch 63, g_loss 0.5892 d_loss 0.1504, time 2442.037\n",
      "Epoch 64, g_loss 0.5889 d_loss 0.1507, time 2477.9897\n",
      "Epoch 65, g_loss 0.5894 d_loss 0.1501, time 2513.8594\n",
      "Epoch 66, g_loss 0.5899 d_loss 0.15, time 2548.3693\n",
      "Epoch 67, g_loss 0.5902 d_loss 0.15, time 2582.8676\n",
      "Epoch 68, g_loss 0.5905 d_loss 0.1498, time 2618.3108\n",
      "Epoch 69, g_loss 0.5889 d_loss 0.151, time 2652.6757\n",
      "Epoch 70, g_loss 0.5842 d_loss 0.152, time 2688.3056\n",
      "Epoch 71, g_loss 0.5864 d_loss 0.1505, time 2723.3801\n",
      "Epoch 72, g_loss 0.5877 d_loss 0.1502, time 2759.0275\n",
      "Epoch 73, g_loss 0.5884 d_loss 0.1499, time 2794.0306\n",
      "Epoch 74, g_loss 0.5894 d_loss 0.1498, time 2828.9418\n",
      "Epoch 75, g_loss 0.5899 d_loss 0.1498, time 2864.7399\n",
      "Epoch 76, g_loss 0.5899 d_loss 0.1501, time 2900.0976\n",
      "Epoch 77, g_loss 0.5911 d_loss 0.1496, time 2935.88\n",
      "Epoch 78, g_loss 0.5921 d_loss 0.1493, time 2970.9844\n",
      "Epoch 79, g_loss 0.5923 d_loss 0.1493, time 3006.0872\n",
      "Epoch 80, g_loss 0.5914 d_loss 0.1497, time 3041.3195\n",
      "Epoch 81, g_loss 0.5903 d_loss 0.1503, time 3077.087\n",
      "Epoch 82, g_loss 0.5904 d_loss 0.1499, time 3112.2303\n",
      "Epoch 83, g_loss 0.5906 d_loss 0.1497, time 3147.0518\n",
      "Epoch 84, g_loss 0.5906 d_loss 0.1497, time 3182.6371\n",
      "Epoch 85, g_loss 0.5907 d_loss 0.1497, time 3218.3984\n",
      "Epoch 86, g_loss 0.5898 d_loss 0.151, time 3254.2731\n",
      "Epoch 87, g_loss 0.5907 d_loss 0.1497, time 3290.1104\n",
      "Epoch 88, g_loss 0.5909 d_loss 0.1496, time 3326.2553\n",
      "Epoch 89, g_loss 0.5908 d_loss 0.1496, time 3362.1019\n",
      "Epoch 90, g_loss 0.5909 d_loss 0.1495, time 3398.1041\n",
      "Epoch 91, g_loss 0.5909 d_loss 0.1495, time 3434.2118\n",
      "Epoch 92, g_loss 0.5909 d_loss 0.1496, time 3470.5908\n",
      "Epoch 93, g_loss 0.5907 d_loss 0.1497, time 3506.6959\n",
      "Epoch 94, g_loss 0.5907 d_loss 0.1497, time 3542.7697\n",
      "Epoch 95, g_loss 0.5907 d_loss 0.1497, time 3578.5903\n",
      "Epoch 96, g_loss 0.5909 d_loss 0.1495, time 3614.5183\n",
      "Epoch 97, g_loss 0.5909 d_loss 0.1496, time 3650.3095\n",
      "Epoch 98, g_loss 0.591 d_loss 0.1495, time 3685.9744\n",
      "Epoch 99, g_loss 0.591 d_loss 0.1495, time 3721.7498\n",
      "Epoch 100, g_loss 0.5904 d_loss 0.1502, time 3757.4689\n",
      "Epoch 101, g_loss 0.5914 d_loss 0.1492, time 3793.4204\n",
      "Epoch 102, g_loss 0.5913 d_loss 0.1493, time 3828.7861\n",
      "Epoch 103, g_loss 0.5914 d_loss 0.1493, time 3864.4318\n",
      "Epoch 104, g_loss 0.5913 d_loss 0.1493, time 3900.0782\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-8a205c5c9d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         _,_, g_loss_val, d_loss_val = sess.run([g_train, d_train, g_loss, d_loss],\n\u001b[0;32m---> 80\u001b[0;31m                                         feed_dict={real_a: batch_x, real_b:batch_y})\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtotal_g_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mg_loss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(networks)\n",
    "\n",
    "real_a = tf.keras.layers.Input(input_shape)\n",
    "real_b = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "mask_a = tf.keras.layers.Input(input_shape)\n",
    "mask_b = tf.keras.layers.Input(input_shape)\n",
    "\n",
    "nf_enc = [16, 32, 32, 32]\n",
    "nf_dec = [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "g_a2b = networks.gan_generator(real_a, nf_enc, nf_dec, flow_out=False)\n",
    "d_a = networks.gan_discriminator(real_a)\n",
    "\n",
    "g_b2a = networks.gan_generator(real_b, nf_enc, nf_dec, flow_out=False)\n",
    "d_b = networks.gan_discriminator(real_b)\n",
    "\n",
    "print(g_a2b.summary())\n",
    "print(d_a.summary())\n",
    "\n",
    "fake_b = g_a2b(real_a)\n",
    "fake_a = g_b2a(real_b)\n",
    "\n",
    "recon_b = g_a2b(fake_a)\n",
    "recon_a = g_b2a(fake_b)\n",
    "\n",
    "fake_a_pred = d_a(fake_a)\n",
    "fake_b_pred = d_b(fake_b)\n",
    "\n",
    "real_a_pred = d_a(real_a)\n",
    "real_b_pred = d_a(real_b)\n",
    "\n",
    "def mse(y_true,y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true-y_pred))\n",
    "\n",
    "def mae(y_true,y_pred):\n",
    "    return tf.reduce_mean(tf.abs(y_true-y_pred))\n",
    "\n",
    "reconstructions = tf.keras.layers.Concatenate(axis=0, name='reconstructions')([recon_a, recon_b])\n",
    "d_predictions = tf.keras.layers.Concatenate(axis=0, name='d_predictions')([fake_a_pred, fake_b_pred])\n",
    "real = tf.keras.layers.Concatenate(axis=0, name='real')([real_a, real_b])\n",
    "\n",
    "g_loss = mse(tf.ones_like(d_predictions), d_predictions) + mae(real, reconstructions)\n",
    "\n",
    "d_A_loss = mse(tf.concat([tf.ones_like(real_a_pred), tf.zeros_like(fake_a_pred)],0), tf.concat([real_a_pred, fake_a_pred],0))\n",
    "d_B_loss = mse(tf.concat([tf.ones_like(real_b_pred), tf.zeros_like(fake_b_pred)],0), tf.concat([real_b_pred, fake_b_pred],0))\n",
    "d_loss = 0.5*(d_A_loss+d_B_loss)\n",
    "\n",
    "lr = 2e-4\n",
    "\n",
    "update_g_a2b = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5, beta2=0.999).minimize(g_loss, var_list=g_a2b.trainable_weights)\n",
    "update_g_b2a = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5, beta2=0.999).minimize(g_loss, var_list=g_b2a.trainable_weights)\n",
    "update_d_a = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5, beta2=0.999).minimize(d_loss, var_list=d_a.trainable_weights)\n",
    "update_d_b = tf.train.AdamOptimizer(learning_rate=lr, beta1=0.5, beta2=0.999).minimize(d_loss, var_list=d_b.trainable_weights)\n",
    "\n",
    "g_train = [update_g_a2b, update_g_b2a]\n",
    "d_train = [update_d_a, update_d_b]\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "count = len(gan_x)//batch_size\n",
    "\n",
    "start = time.time()\n",
    "save_step = 100\n",
    "\n",
    "for i in range(1000):\n",
    "    random.shuffle(gan_x)\n",
    "    random.shuffle(gan_y)\n",
    "    \n",
    "    total_g_loss = 0\n",
    "    total_d_loss = 0\n",
    "    \n",
    "    for j in range(count):\n",
    "        batch_x = gan_x[j:j+batch_size]\n",
    "        batch_y = gan_y[j:j+batch_size]\n",
    "        \n",
    "        _,_, g_loss_val, d_loss_val = sess.run([g_train, d_train, g_loss, d_loss],\n",
    "                                        feed_dict={real_a: batch_x, real_b:batch_y})\n",
    "        \n",
    "        total_g_loss+=g_loss_val\n",
    "        total_d_loss+=d_loss_val\n",
    "        \n",
    "    print('Epoch {}, g_loss {} d_loss {}, time {}'.format(i,round(total_g_loss/count,4),round(total_d_loss/count,4),round(time.time()-start,4)))\n",
    "    \n",
    "    if i % save_step == 0:\n",
    "        g_a2b.save('../models/g_a2b.h5')\n",
    "        g_b2a.save('../models/g_a2b.h5')\n",
    "        d_a.save('../models/d_a.h5')\n",
    "        d_b.save('../models/d_b.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = gan_x[0]\n",
    "plt.imshow(np.squeeze(img),'gray')\n",
    "plt.show()\n",
    "pred = g_a2b.predict(np.expand_dims(img,0))\n",
    "plt.imshow(np.squeeze(pred[0]),'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.2555 - acc: 0.4922\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0735 - acc: 0.9146\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0163 - acc: 0.9849\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0198 - acc: 0.9805\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0197 - acc: 0.9805\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0196 - acc: 0.9805\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0196 - acc: 0.9805\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 8s 8ms/step - loss: 0.0196 - acc: 0.9805\n",
      "Epoch 9/20\n",
      " 448/1000 [============>.................] - ETA: 4s - loss: 0.0191 - acc: 0.9810"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-65e3835d2aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moutputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moutputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    199\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    503\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(networks)\n",
    "x_train = np.concatenate((gan_x,gan_y), axis=0)\n",
    "\n",
    "d=networks.gan_discriminator(real_a)\n",
    "outputs_shape=tuple(d.output.shape.as_list())\n",
    "# print(outputs.shape.as_list())\n",
    "\n",
    "y_train = np.concatenate((np.zeros((len(gan_x),)+outputs_shape[1:]), np.ones((len(gan_x),)+outputs_shape[1:])))\n",
    "d.compile('adam', loss='mse', metrics=['acc'])\n",
    "d.fit(x_train, y_train, epochs=20, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11426204"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(gan_y[0]-np.zeros_like(gan_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
